from langchain_core.messages import SystemMessage, HumanMessage
from langchain_core.output_parsers import JsonOutputParser
from langchain_core.prompts import ChatPromptTemplate
from core.models import init_models
from .state import TodoState, Plan

def generate_plan(state: TodoState) -> TodoState:
    print("ğŸ¤– ç”Ÿæˆè®¡åˆ’ä¸­...")
    llm = init_models()
    
    # ä½¿ç”¨ JsonOutputParserï¼Œå®ƒèƒ½è‡ªåŠ¨å¤„ç† Markdown ä»£ç å—åŒ…è£¹çš„ JSON
    parser = JsonOutputParser(pydantic_object=Plan)
    
    system_prompt = """ä½ æ˜¯ä¸“ä¸šçš„ä¸ªäººè§„åˆ’åŠ©æ‰‹ã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„æè¿°ï¼Œåˆ¶å®šä¸€ä»½è¯¦ç»†çš„å¾…åŠäº‹é¡¹æ¸…å•ã€‚
{format_instructions}

ä¼˜å…ˆçº§çš„åˆ¤æ–­æ ‡å‡†ï¼š
- high: ç´§æ€¥ä¸”é‡è¦
- medium: é‡è¦ä½†ä¸ç´§æ€¥
- low: ä¸é‡è¦æˆ–ä¸ç´§æ€¥

è¯·ç¡®ä¿ç”Ÿæˆçš„è®¡åˆ’å…·æœ‰å¯æ‰§è¡Œæ€§ï¼Œå¹¶åˆç†åˆ†é…ä¼˜å…ˆçº§ã€‚
"""
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_prompt),
        ("human", "{user_input}")
    ])
    
    chain = prompt | llm | parser
    
    try:
        # parser è¿”å›çš„æ˜¯å­—å…¸ï¼Œæˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸º Plan å¯¹è±¡
        response_dict = chain.invoke({
            "user_input": state["user_input"],
            "format_instructions": parser.get_format_instructions()
        })
        
        plan = Plan(**response_dict)
        return {"plan": plan, "error": None}
    except Exception as e:
        print(f"âŒ ç”Ÿæˆè®¡åˆ’å¤±è´¥: {e}")
        return {"plan": None, "error": str(e)}
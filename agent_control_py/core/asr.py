# core/asr.py
import io
import os
from faster_whisper import WhisperModel


class ASRManager:
    def __init__(self):
        # 1. è®¾å®šç›¸å¯¹è·¯å¾„
        base_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.model_path = os.path.join(base_dir, "models", "asr")

        # å¦‚æœç›®å½•ä¸å­˜åœ¨åˆ™åˆ›å»º
        if not os.path.exists(self.model_path):
            os.makedirs(self.model_path, exist_ok=True)

        self.model_size = "base"
        self.model = None  # æ‡’åŠ è½½ï¼šåˆå§‹ä¸åŠ è½½æ¨¡å‹
        print(f"ğŸš€ [ASR] Manager å·²åˆå§‹åŒ– (ç­‰å¾…é¦–æ¬¡è°ƒç”¨åŠ è½½æ¨¡å‹)")

    def _load_model(self):
        if self.model is None:
            print(f"ğŸš€ [ASR] æ­£åœ¨åŠ è½½ Faster-Whisper æ¨¡å‹...")
            print(f"ğŸ“‚ [ASR] æ¨¡å‹å­˜æ”¾ä½ç½®: {self.model_path}")
            # compute_type="int8" ä¿è¯åœ¨æ€§èƒ½æœ‰é™çš„ç”µè„‘ä¸Šè¿è¡Œå¿«é€Ÿ
            # cpu_threads=4 é™åˆ¶CPUå ç”¨
            self.model = WhisperModel(
                self.model_size,
                device="cpu",
                compute_type="int8",
                cpu_threads=4,
                download_root=self.model_path
            )
            print("âœ… [ASR] æ¨¡å‹åŠ è½½å®Œæˆ")

    def transcribe(self, audio_bytes: bytes) -> str:
        """è¯†åˆ«éŸ³é¢‘å­—èŠ‚æµ"""
        try:
            self._load_model() # ç¡®ä¿æ¨¡å‹å·²åŠ è½½
            audio_io = io.BytesIO(audio_bytes)
            # language="zh" å¼ºåˆ¶ä¸­æ–‡
            # ç§»é™¤ initial_promptï¼Œé˜²æ­¢é™éŸ³æ—¶æ¨¡å‹å¤è¯»æç¤ºè¯
            segments, _ = self.model.transcribe(
                audio_io,
                language="zh",
                beam_size=1,
                vad_filter=True
            )
            return "".join([s.text for s in segments]).strip()
        except Exception as e:
            print(f"âŒ [ASR] è¯†åˆ«å¼‚å¸¸: {e}")
            return ""


# å®ä¾‹åŒ–å•ä¾‹
asr_manager = ASRManager()